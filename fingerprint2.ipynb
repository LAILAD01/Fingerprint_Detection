{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1a7afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the images array: (6000, 128, 128, 1)\n",
      "Number of labels: 0\n"
     ]
    }
   ],
   "source": [
    "#data preprocessing\n",
    "import os\n",
    "from PIL import Image, ImageEnhance\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_images(directory, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []  # This could be modified to parse actual labels if available\n",
    "\n",
    "    # Iterate over files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    # Enhance image contrast\n",
    "                    enhancer = ImageEnhance.Contrast(img)\n",
    "                    img = enhancer.enhance(2.0)  # Enhance contrast; you can adjust the factor as needed\n",
    "\n",
    "                    # Resize and convert to grayscale\n",
    "                    img = img.resize(target_size).convert('L')\n",
    "\n",
    "                    # Convert to numpy array and normalize\n",
    "                    img_array = np.array(img) / 255.0\n",
    "                    images.append(img_array)\n",
    "                    # Extract labels from filename if applicable\n",
    "                    # labels.append(extract_label_from_filename(filename))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "    # Convert list of arrays to a 4D NumPy array: (num_samples, height, width, channels)\n",
    "    images = np.array(images)[..., np.newaxis]  # Adding channel dimension for grayscale\n",
    "    return images, labels\n",
    "\n",
    "# Usage\n",
    "directory = '/Users/laila_1/Downloads/SOCOFing/Real'  # Update this path to where your dataset is stored\n",
    "images, labels = load_and_preprocess_images(directory)\n",
    "\n",
    "print(\"Shape of the images array:\", images.shape)  # Should be (num_samples, 128, 128, 1)\n",
    "print(\"Number of labels:\", len(labels))  # Should match num_samples if labels are processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580b707d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 97\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Assuming `image` is your input image data as a NumPy array of shape (num_examples, height, width, channels)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Initialize and run the convolution\u001b[39;00m\n\u001b[1;32m     96\u001b[0m convnet \u001b[38;5;241m=\u001b[39m ConvNet(images)\n\u001b[0;32m---> 97\u001b[0m feature_map \u001b[38;5;241m=\u001b[39m \u001b[43mconvnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature_map\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature_map)\n",
      "Cell \u001b[0;32mIn[5], line 89\u001b[0m, in \u001b[0;36mConvNet.conv_forward\u001b[0;34m(self, padding_mode)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 col_start \u001b[38;5;241m=\u001b[39m j \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride\n\u001b[1;32m     88\u001b[0m                 local_region \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_input[n, row_start:row_start \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_h, col_start:col_start \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_w, :]\n\u001b[0;32m---> 89\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_map[n, i, j, f] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_region\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[f]\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_map)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2123\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2119\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[0;32m-> 2123\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[1;32m   2124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2125\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2126\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;124;03m    Sum of array elements over a given axis.\u001b[39;00m\n\u001b[1;32m   2128\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;124;03m    15\u001b[39;00m\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, _gentype):\n\u001b[1;32m   2247\u001b[0m         \u001b[38;5;66;03m# 2018-02-25, 1.15.0\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#data preprocessing\n",
    "import os\n",
    "from PIL import Image, ImageEnhance\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_images(directory, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []  # This could be modified to parse actual labels if available\n",
    "\n",
    "    # Iterate over files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    # Enhance image contrast\n",
    "                    enhancer = ImageEnhance.Contrast(img)\n",
    "                    img = enhancer.enhance(2.0)  # Enhance contrast; you can adjust the factor as needed\n",
    "\n",
    "                    # Resize and convert to grayscale\n",
    "                    img = img.resize(target_size).convert('L')\n",
    "\n",
    "                    # Convert to numpy array and normalize\n",
    "                    img_array = np.array(img) / 255.0\n",
    "                    images.append(img_array)\n",
    "                    # Extract labels from filename if applicable\n",
    "                    # labels.append(extract_label_from_filename(filename))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "    # Convert list of arrays to a 4D NumPy array: (num_samples, height, width, channels)\n",
    "    images = np.array(images)[..., np.newaxis]  # Adding channel dimension for grayscale\n",
    "    return images, labels\n",
    "\n",
    "# Usage\n",
    "directory = '/Users/laila_1/Downloads/SOCOFing/Real'  # Update this path to where your dataset is stored\n",
    "images, labels = load_and_preprocess_images(directory)\n",
    "\n",
    "\n",
    "class ConvNet:\n",
    "    def __init__(self, image):\n",
    "        # Hyperparameters\n",
    "        self.num_filters = 8  # Increased number of filters\n",
    "        self.filter_h = 3\n",
    "        self.filter_w = 3\n",
    "        self.stride = 1\n",
    "\n",
    "        # Weights initialization\n",
    "        self.filters_weights = np.random.randn(self.num_filters, self.filter_h, self.filter_w)\n",
    "        self.bias = np.random.randn(self.num_filters, 1, 1)\n",
    "\n",
    "        # Image dimensions\n",
    "        self.examples = image.shape[0]\n",
    "        self.img_height = image.shape[1]\n",
    "        self.img_width = image.shape[2]\n",
    "\n",
    "        # Keep original input for later\n",
    "        self.last_input = image\n",
    "\n",
    "    # Activation function\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0.0, x)\n",
    "\n",
    "    # Padding function\n",
    "    def zero_pad(self, image_to_pad, pad_h, pad_w):\n",
    "        return np.pad(image_to_pad, ((0, 0), (pad_h, pad_h), (pad_w, pad_w), (0, 0)), 'constant', constant_values=(0, 0))\n",
    "\n",
    "    # Convolution forward propagation\n",
    "    def conv_forward(self, padding_mode):\n",
    "        if padding_mode == \"same\":\n",
    "            pad_h = (self.filter_h - 1) // 2\n",
    "            pad_w = (self.filter_w - 1) // 2\n",
    "            self.last_input = self.zero_pad(self.last_input, pad_h, pad_w)\n",
    "            self.img_height += 2 * pad_h\n",
    "            self.img_width += 2 * pad_w\n",
    "\n",
    "        self.fm_height = (self.img_height - self.filter_h) // self.stride + 1\n",
    "        self.fm_width = (self.img_width - self.filter_w) // self.stride + 1\n",
    "        self.f_map = np.zeros((self.examples, self.fm_height, self.fm_width, self.num_filters))\n",
    "\n",
    "        for n in range(self.examples):\n",
    "            for i in range(self.fm_height):\n",
    "                for j in range(self.fm_width):\n",
    "                    for f in range(self.num_filters):\n",
    "                        row_start = i * self.stride\n",
    "                        col_start = j * self.stride\n",
    "                        local_region = self.last_input[n, row_start:row_start + self.filter_h, col_start:col_start + self.filter_w, :]\n",
    "                        self.f_map[n, i, j, f] = np.sum(local_region * self.filters_weights[f]) + self.bias[f]\n",
    "\n",
    "        return self.relu(self.f_map)\n",
    "\n",
    "# Example usage\n",
    "# Assuming `image` is your input image data as a NumPy array of shape (num_examples, height, width, channels)\n",
    "# Initialize and run the convolution\n",
    "convnet = ConvNet(images)\n",
    "feature_map = convnet.conv_forward('same')\n",
    "print(feature_map.shape)\n",
    "print(feature_map)\n",
    "\n",
    "# Continue with MaxPooling, Flatten, and Neural Network classes with similar revisions...\n",
    "class MaxPooling:\n",
    "    def __init__(self, f_map, pool_h=2, pool_w=2, stride=2):\n",
    "        self.pool_filter_h = pool_h\n",
    "        self.pool_filter_w = pool_w\n",
    "        self.stride = stride\n",
    "\n",
    "        self.examples = f_map.shape[0]\n",
    "        self.fm_height = f_map.shape[1]\n",
    "        self.fm_width = f_map.shape[2]\n",
    "        self.channels = f_map.shape[3]\n",
    "        self.last_input = f_map\n",
    "\n",
    "    def max_forward(self):\n",
    "        height_out = (self.fm_height - self.pool_filter_h) // self.stride + 1\n",
    "        width_out = (self.fm_width - self.pool_filter_w) // self.stride + 1\n",
    "        self.pool_output = np.zeros((self.examples, height_out, width_out, self.channels))\n",
    "\n",
    "        for n in range(self.examples):\n",
    "            for c in range(self.channels):\n",
    "                for i in range(height_out):\n",
    "                    for j in range(width_out):\n",
    "                        row_start = i * self.stride\n",
    "                        col_start = j * self.stride\n",
    "                        window = self.last_input[n, row_start:row_start + self.pool_filter_h, col_start:col_start + self.pool_filter_w, c]\n",
    "                        self.pool_output[n, i, j, c] = np.max(window)\n",
    "\n",
    "        return self.pool_output\n",
    "\n",
    "\n",
    "def flatten_layer(f_map):\n",
    "    flat_output = f_map.reshape(f_map.shape[0], -1)\n",
    "    return flat_output\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, num_classes, hidden_units=100, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights1 = np.random.randn(input_size, hidden_units) * 0.01\n",
    "        self.bias1 = np.zeros((1, hidden_units))\n",
    "        self.weights2 = np.random.randn(hidden_units, num_classes) * 0.01\n",
    "        self.bias2 = np.zeros((1, num_classes))\n",
    "\n",
    "    def sigmoid(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "    def softmax(self, Z):\n",
    "        expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "        return expZ / np.sum(expZ, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.Z1 = np.dot(X, self.weights1) + self.bias1\n",
    "        self.A1 = self.sigmoid(self.Z1)\n",
    "        self.Z2 = np.dot(self.A1, self.weights2) + self.bias2\n",
    "        self.A2 = self.softmax(self.Z2)\n",
    "        return self.A2\n",
    "\n",
    "    def compute_loss(self, Y, Y_hat):\n",
    "        m = Y.shape[0]\n",
    "        log_probs = -np.log(Y_hat[range(m), Y])\n",
    "        loss = np.sum(log_probs) / m\n",
    "        return loss\n",
    "\n",
    "    def backprop(self, X, Y, Y_hat):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Gradient of loss w.r.t. output\n",
    "        dZ2 = Y_hat\n",
    "        dZ2[range(m), Y] -= 1\n",
    "        dW2 = np.dot(self.A1.T, dZ2) / m\n",
    "        dB2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        dA1 = np.dot(dZ2, self.weights2.T)\n",
    "        dZ1 = dA1 * self.A1 * (1 - self.A1)  # Sigmoid derivative\n",
    "        dW1 = np.dot(X.T, dZ1) / m\n",
    "        dB1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.weights1 -= self.learning_rate * dW1\n",
    "        self.bias1 -= self.learning_rate * dB1\n",
    "        self.weights2 -= self.learning_rate * dW2\n",
    "        self.bias2 -= self.learning_rate * dB2\n",
    "\n",
    "\n",
    "# Assuming you have labels `y` that are integer class labels\n",
    "nn = NeuralNetwork(flattened_output.shape[1], num_classes=10)  # num_classes depends on your dataset\n",
    "predictions = nn.forward(flattened_output)\n",
    "loss = nn.compute_loss(y, predictions)\n",
    "nn.backprop(flattened_output, y, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c44dc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming the preprocessing function returns images in the correct format\u001b[39;00m\n\u001b[1;32m      5\u001b[0m convnet \u001b[38;5;241m=\u001b[39m ConvNet(images)\n\u001b[0;32m----> 6\u001b[0m feature_map \u001b[38;5;241m=\u001b[39m \u001b[43mconvnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature map shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, feature_map\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature map output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, feature_map)\n",
      "Cell \u001b[0;32mIn[2], line 50\u001b[0m, in \u001b[0;36mConvNet.conv_forward\u001b[0;34m(self, padding_mode)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 row_start \u001b[38;5;241m=\u001b[39m i \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride\n\u001b[1;32m     49\u001b[0m                 col_start \u001b[38;5;241m=\u001b[39m j \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride\n\u001b[0;32m---> 50\u001b[0m                 local_region \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mrow_start\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_start\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcol_start\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     51\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_map[n, i, j, f] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(local_region \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters_weights[f]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias[f]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_map)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming you have a function to load and preprocess images\n",
    "images, labels = load_and_preprocess_images('/Users/laila_1/Downloads/SOCOFing/Real')\n",
    "\n",
    "# Assuming the preprocessing function returns images in the correct format\n",
    "convnet = ConvNet(images)\n",
    "feature_map = convnet.conv_forward('same')\n",
    "print(\"Feature map shape:\", feature_map.shape)\n",
    "print(\"Feature map output:\", feature_map)\n",
    "\n",
    "# Proceed with max pooling, flattening, and feeding into a neural network\n",
    "max_pooling = MaxPooling(feature_map)\n",
    "pooled_feature_map = max_pooling.max_forward()\n",
    "flattened_output = flatten_layer(pooled_feature_map)\n",
    "\n",
    "# Assuming you have labels formatted correctly for your dataset\n",
    "nn = NeuralNetwork(flattened_output.shape[1], num_classes=10)  # Adjust num_classes based on your actual dataset\n",
    "predictions = nn.forward(flattened_output)\n",
    "loss = nn.compute_loss(labels, predictions)\n",
    "nn.backprop(flattened_output, labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c255dc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch feature map shape: (100, 128, 128, 8)\n",
      "Processed batch feature map shape: (100, 128, 128, 8)\n",
      "Processed batch feature map shape: (100, 128, 128, 8)\n",
      "Processed batch feature map shape: (100, 128, 128, 8)\n",
      "Processed batch feature map shape: (100, 128, 128, 8)\n",
      "Processed batch feature map shape: (100, 128, 128, 8)\n",
      "Processed batch feature map shape: (100, 128, 128, 8)\n",
      "Processed batch feature map shape: (100, 128, 128, 8)\n",
      "Processed batch feature map shape: (100, 128, 128, 8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "def load_and_preprocess_images(directory, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []  # This could be modified to parse actual labels if available\n",
    "\n",
    "    # Iterate over files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    # Enhance image contrast\n",
    "                    enhancer = ImageEnhance.Contrast(img)\n",
    "                    img = enhancer.enhance(2.0)  # Enhance contrast; you can adjust the factor as needed\n",
    "\n",
    "                    # Resize and convert to grayscale\n",
    "                    img = img.resize(target_size).convert('L')\n",
    "\n",
    "                    # Convert to numpy array and normalize\n",
    "                    img_array = np.array(img) / 255.0\n",
    "                    images.append(img_array)\n",
    "                    # Extract labels from filename if applicable\n",
    "                    # labels.append(extract_label_from_filename(filename))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {filename}: {e}\")\n",
    "\n",
    "    # Convert list of arrays to a 4D NumPy array: (num_samples, height, width, channels)\n",
    "    images = np.array(images)[..., np.newaxis]  # Adding channel dimension for grayscale\n",
    "    return images, labels\n",
    "\n",
    "def batch_process(images, batch_size=100):\n",
    "    num_batches = len(images) // batch_size + (1 if len(images) % batch_size != 0 else 0)\n",
    "    for i in range(num_batches):\n",
    "        batch_images = images[i * batch_size:(i + 1) * batch_size]\n",
    "        yield batch_images\n",
    "\n",
    "# Initialize ConvNet\n",
    "class ConvNet:\n",
    "    def __init__(self, num_filters=8, filter_h=3, filter_w=3, stride=1):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_h = filter_h\n",
    "        self.filter_w = filter_w\n",
    "        self.stride = stride\n",
    "        self.filters_weights = np.random.randn(self.num_filters, self.filter_h, self.filter_w)\n",
    "        self.bias = np.random.randn(self.num_filters, 1, 1)\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0.0, x)\n",
    "\n",
    "    def zero_pad(self, image_to_pad, pad_h, pad_w):\n",
    "        return np.pad(image_to_pad, ((0, 0), (pad_h, pad_h), (pad_w, pad_w), (0, 0)), 'constant', constant_values=(0, 0))\n",
    "\n",
    "    def conv_forward(self, image, padding_mode):\n",
    "        if padding_mode == \"same\":\n",
    "            pad_h = (self.filter_h - 1) // 2\n",
    "            pad_w = (self.filter_w - 1) // 2\n",
    "            image = self.zero_pad(image, pad_h, pad_w)\n",
    "        img_height = image.shape[1]\n",
    "        img_width = image.shape[2]\n",
    "        fm_height = (img_height - self.filter_h) // self.stride + 1\n",
    "        fm_width = (img_width - self.filter_w) // self.stride + 1\n",
    "        f_map = np.zeros((image.shape[0], fm_height, fm_width, self.num_filters))\n",
    "        for n in range(image.shape[0]):\n",
    "            for i in range(fm_height):\n",
    "                for j in range(fm_width):\n",
    "                    for f in range(self.num_filters):\n",
    "                        row_start = i * self.stride\n",
    "                        col_start = j * self.stride\n",
    "                        local_region = image[n, row_start:row_start + self.filter_h, col_start:col_start + self.filter_w, :]\n",
    "                        f_map[n, i, j, f] = np.sum(local_region * self.filters_weights[f]) + self.bias[f]\n",
    "        return self.relu(f_map)\n",
    "\n",
    "directory = '/Users/laila_1/Downloads/SOCOFing/Real'  # Update this path to where your dataset is stored\n",
    "images, labels = load_and_preprocess_images(directory)\n",
    "convnet = ConvNet()\n",
    "\n",
    "for batch_images in batch_process(images, batch_size=100):\n",
    "    feature_map = convnet.conv_forward(batch_images, 'same')\n",
    "    print(\"Processed batch feature map shape:\", feature_map.shape)\n",
    "    # Continue with MaxPooling, Flatten, and Neural Network layers...\n",
    "class MaxPooling:\n",
    "    def __init__(self, f_map, pool_h=2, pool_w=2, stride=2):\n",
    "        self.pool_filter_h = pool_h\n",
    "        self.pool_filter_w = pool_w\n",
    "        self.stride = stride\n",
    "\n",
    "        self.examples = f_map.shape[0]\n",
    "        self.fm_height = f_map.shape[1]\n",
    "        self.fm_width = f_map.shape[2]\n",
    "        self.channels = f_map.shape[3]\n",
    "        self.last_input = f_map\n",
    "\n",
    "    def max_forward(self):\n",
    "        height_out = (self.fm_height - self.pool_filter_h) // self.stride + 1\n",
    "        width_out = (self.fm_width - self.pool_filter_w) // self.stride + 1\n",
    "        self.pool_output = np.zeros((self.examples, height_out, width_out, self.channels))\n",
    "\n",
    "        for n in range(self.examples):\n",
    "            for c in range(self.channels):\n",
    "                for i in range(height_out):\n",
    "                    for j in range(width_out):\n",
    "                        row_start = i * self.stride\n",
    "                        col_start = j * self.stride\n",
    "                        window = self.last_input[n, row_start:row_start + self.pool_filter_h, col_start:col_start + self.pool_filter_w, c]\n",
    "                        self.pool_output[n, i, j, c] = np.max(window)\n",
    "\n",
    "        return self.pool_output\n",
    "\n",
    "\n",
    "def flatten_layer(f_map):\n",
    "    flat_output = f_map.reshape(f_map.shape[0], -1)\n",
    "    return flat_output\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, num_classes, hidden_units=100, learning_rate=0.01):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights1 = np.random.randn(input_size, hidden_units) * 0.01\n",
    "        self.bias1 = np.zeros((1, hidden_units))\n",
    "        self.weights2 = np.random.randn(hidden_units, num_classes) * 0.01\n",
    "        self.bias2 = np.zeros((1, num_classes))\n",
    "\n",
    "    def sigmoid(self, Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "    def softmax(self, Z):\n",
    "        expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "        return expZ / np.sum(expZ, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.Z1 = np.dot(X, self.weights1) + self.bias1\n",
    "        self.A1 = self.sigmoid(self.Z1)\n",
    "        self.Z2 = np.dot(self.A1, self.weights2) + self.bias2\n",
    "        self.A2 = self.softmax(self.Z2)\n",
    "        return self.A2\n",
    "\n",
    "    def compute_loss(self, Y, Y_hat):\n",
    "        m = Y.shape[0]\n",
    "        log_probs = -np.log(Y_hat[range(m), Y])\n",
    "        loss = np.sum(log_probs) / m\n",
    "        return loss\n",
    "\n",
    "    def backprop(self, X, Y, Y_hat):\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        # Gradient of loss w.r.t. output\n",
    "        dZ2 = Y_hat\n",
    "        dZ2[range(m), Y] -= 1\n",
    "        dW2 = np.dot(self.A1.T, dZ2) / m\n",
    "        dB2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "        \n",
    "        dA1 = np.dot(dZ2, self.weights2.T)\n",
    "        dZ1 = dA1 * self.A1 * (1 - self.A1)  # Sigmoid derivative\n",
    "        dW1 = np.dot(X.T, dZ1) / m\n",
    "        dB1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.weights1 -= self.learning_rate * dW1\n",
    "        self.bias1 -= self.learning_rate * dB1\n",
    "        self.weights2 -= self.learning_rate * dW2\n",
    "        self.bias2 -= self.learning_rate * dB2\n",
    "\n",
    "\n",
    "# Assuming you have labels `y` that are integer class labels\n",
    "nn = NeuralNetwork(flattened_output.shape[1], num_classes=10)  # num_classes depends on your dataset\n",
    "predictions = nn.forward(flattened_output)\n",
    "loss = nn.compute_loss(y, predictions)\n",
    "nn.backprop(flattened_output, y, predictions)\n",
    "\n",
    "# After the neural network output is computed\n",
    "predicted_classes = np.argmax(network_output, axis=1)\n",
    "print(\"Predicted classes:\", predicted_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42990b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
